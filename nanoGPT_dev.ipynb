{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj+pH8G2QDBbv6yxb/xHGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyMhatre/nanoGPT/blob/main/nanoGPT_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# nanoGPT from scratch"
      ],
      "metadata": {
        "id": "5Za5YBNPcDeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only *validation.csv* is being used to reduce training time."
      ],
      "metadata": {
        "id": "7730Ktm1dJ2w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnj-C9SFYT7l",
        "outputId": "6ae0d60f-da20-4f41-bd17-e819fbff3fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1-625683540.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/thedevastator/tinystories-narrative-classification?dataset_version_number=2&file_name=validation.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.74M/5.74M [00:00<00:00, 101MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of validation.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:                                                 text\n",
            "0  Spot. Spot saw the shiny car and said, \"Wow, K...\n",
            "1  Once upon a time, in a big forest, there lived...\n",
            "2  Once upon a time, in a small yard, there was a...\n",
            "3  Once upon a time, there was a thoughtful girl ...\n",
            "4  Once upon a time, there was a kind farmer. He ...\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"validation.csv\"\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"thedevastator/tinystories-narrative-classification\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12997522"
      },
      "source": [
        "df.to_csv('input.txt', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "YKRE2qT9a39Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters\", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkBgG1VIb2cb",
        "outputId": "e8967d02-05d2-4616-b624-60043895c090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters 19349772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSeMYda6cIV3",
        "outputId": "5ecdcc16-cfe0-435f-ffe4-a5dd4ef48731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Spot. Spot saw the shiny car and said, \"\"Wow, Kitty, your car is so bright and clean!\"\" Kitty smiled and replied, \"\"Thank you, Spot. I polish it every day.\"\"\n",
            "\n",
            "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.\"\n",
            "\"Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
            "\n",
            "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"\"Why are you sad, Roxy?\"\"\n",
            "\n",
            "Roxy told Billy about the icy hill and how she couldn't climb it. Billy said, \"\"I have an idea! Let's find\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPhd9e8HcYcn",
        "outputId": "d664a407-4c16-4d47-fd90-9a4f2a6cc585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"#$&'()*+,-./0123456789:;<?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz¦©­±´ÂÃâðœŠŸŽ˜“”‹€™\n",
            "101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwY5O_ILdZGX",
        "outputId": "cc806ceb-eeab-4c72-8457-896cc4f38a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[63, 64, 64, 1, 75, 63, 60, 73, 60]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding text dataset into a torch.Tensor"
      ],
      "metadata": {
        "id": "NBhEekV7dtwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6s4cdend2tb",
        "outputId": "d23e747a-5848-4390-a930-c6102fa2e93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([19349772]) torch.int64\n",
            "tensor([ 3, 48, 71, 70, 75, 14,  1, 48, 71, 70, 75,  1, 74, 56, 78,  1, 75, 63,\n",
            "        60,  1, 74, 63, 64, 69, 80,  1, 58, 56, 73,  1, 56, 69, 59,  1, 74, 56,\n",
            "        64, 59, 12,  1,  3,  3, 52, 70, 78, 12,  1, 40, 64, 75, 75, 80, 12,  1,\n",
            "        80, 70, 76, 73,  1, 58, 56, 73,  1, 64, 74,  1, 74, 70,  1, 57, 73, 64,\n",
            "        62, 63, 75,  1, 56, 69, 59,  1, 58, 67, 60, 56, 69,  2,  3,  3,  1, 40,\n",
            "        64, 75, 75, 80,  1, 74, 68, 64, 67, 60, 59,  1, 56, 69, 59,  1, 73, 60,\n",
            "        71, 67, 64, 60, 59, 12,  1,  3,  3, 49, 63, 56, 69, 66,  1, 80, 70, 76,\n",
            "        12,  1, 48, 71, 70, 75, 14,  1, 38,  1, 71, 70, 67, 64, 74, 63,  1, 64,\n",
            "        75,  1, 60, 77, 60, 73, 80,  1, 59, 56, 80, 14,  3,  3,  0,  0, 30, 61,\n",
            "        75, 60, 73,  1, 71, 67, 56, 80, 64, 69, 62,  1, 78, 64, 75, 63,  1, 75,\n",
            "        63, 60,  1, 58, 56, 73, 12,  1, 40, 64, 75, 75, 80,  1, 56, 69, 59,  1,\n",
            "        48, 71, 70, 75,  1, 61, 60, 67, 75,  1, 75, 63, 64, 73, 74, 75, 80, 14,\n",
            "         1, 49, 63, 60, 80,  1, 61, 70, 76, 69, 59,  1, 56,  1, 74, 68, 56, 67,\n",
            "        67,  1, 71, 70, 69, 59,  1, 78, 64, 75, 63,  1, 58, 67, 60, 56, 73,  1,\n",
            "        78, 56, 75, 60, 73, 14,  1, 49, 63, 60, 80,  1, 59, 73, 56, 69, 66,  1,\n",
            "        75, 63, 60,  1, 78, 56, 75, 60, 73,  1, 56, 69, 59,  1, 61, 60, 67, 75,\n",
            "         1, 77, 60, 73, 80,  1, 63, 56, 71, 71, 80, 14,  1, 49, 63, 60, 80,  1,\n",
            "        71, 67, 56, 80, 60, 59,  1, 75, 70, 62, 60, 75, 63, 60, 73,  1, 56, 67,\n",
            "        67,  1, 59, 56, 80,  1, 56, 69, 59,  1, 57, 60, 58, 56, 68, 60,  1, 57,\n",
            "        60, 74, 75,  1, 61, 73, 64, 60, 69, 59, 74, 14,  3,  0,  3, 44, 69, 58,\n",
            "        60,  1, 76, 71, 70, 69,  1, 56,  1, 75, 64, 68, 60, 12,  1, 64, 69,  1,\n",
            "        56,  1, 57, 64, 62,  1, 61, 70, 73, 60, 74, 75, 12,  1, 75, 63, 60, 73,\n",
            "        60,  1, 67, 64, 77, 60, 59,  1, 56,  1, 73, 63, 64, 69, 70, 58, 60, 73,\n",
            "        70, 74,  1, 69, 56, 68, 60, 59,  1, 47, 70, 79, 80, 14,  1, 47, 70, 79,\n",
            "        80,  1, 67, 70, 77, 60, 59,  1, 75, 70,  1, 58, 67, 64, 68, 57, 14,  1,\n",
            "        48, 63, 60,  1, 58, 67, 64, 68, 57, 60, 59,  1, 75, 73, 60, 60, 74, 12,\n",
            "         1, 73, 70, 58, 66, 74, 12,  1, 56, 69, 59,  1, 63, 64, 67, 67, 74, 14,\n",
            "         1, 44, 69, 60,  1, 59, 56, 80, 12,  1, 47, 70, 79, 80,  1, 61, 70, 76,\n",
            "        69, 59,  1, 56, 69,  1, 64, 58, 80,  1, 63, 64, 67, 67, 14,  1, 48, 63,\n",
            "        60,  1, 63, 56, 59,  1, 69, 60, 77, 60, 73,  1, 74, 60, 60, 69,  1, 56,\n",
            "        69, 80, 75, 63, 64, 69, 62,  1, 67, 64, 66, 60,  1, 64, 75,  1, 57, 60,\n",
            "        61, 70, 73, 60, 14,  1, 38, 75,  1, 78, 56, 74,  1, 74, 63, 64, 69, 80,\n",
            "         1, 56, 69, 59,  1, 58, 70, 67, 59, 12,  1, 56, 69, 59,  1, 74, 63, 60,\n",
            "         1, 78, 56, 69, 75, 60, 59,  1, 75, 70,  1, 58, 67, 64, 68, 57,  1, 64,\n",
            "        75, 14,  0,  0, 47, 70, 79, 80,  1, 75, 73, 64, 60, 59,  1, 75, 70,  1,\n",
            "        58, 67, 64, 68, 57,  1, 75, 63, 60,  1, 64, 58, 80,  1, 63, 64, 67, 67,\n",
            "        12,  1, 57, 76, 75,  1, 64, 75,  1, 78, 56, 74,  1, 77, 60, 73, 80,  1,\n",
            "        74, 67, 64, 71, 71, 60, 73, 80, 14,  1, 48, 63, 60,  1, 75, 73, 64, 60,\n",
            "        59,  1, 56, 62, 56, 64, 69,  1, 56, 69, 59,  1, 56, 62, 56, 64, 69, 12,\n",
            "         1, 57, 76, 75,  1, 74, 63, 60,  1, 66, 60, 71, 75,  1, 61, 56, 67, 67,\n",
            "        64, 69, 62,  1, 59, 70, 78, 69, 14,  1, 47, 70, 79, 80,  1, 78, 56, 74,\n",
            "         1, 74, 56, 59, 14,  1, 48, 63, 60,  1, 78, 56, 69, 75, 60, 59,  1, 75,\n",
            "        70,  1, 58, 67, 64, 68, 57,  1, 75, 63, 60,  1, 64, 58, 80,  1, 63, 64,\n",
            "        67, 67,  1, 74, 70,  1, 68, 76, 58, 63, 14,  1, 49, 63, 60, 69, 12,  1,\n",
            "        74, 63, 60,  1, 74, 56, 78,  1, 56,  1, 67, 64, 75, 75, 67, 60,  1, 57,\n",
            "        64, 73, 59,  1, 69, 56, 68, 60, 59,  1, 31, 64, 67, 67, 80, 14,  1, 31,\n",
            "        64, 67, 67, 80,  1, 74, 56, 78,  1, 75, 63, 56, 75,  1, 47, 70, 79, 80,\n",
            "         1, 78, 56, 74,  1, 74, 56, 59,  1, 56, 69, 59,  1, 56, 74, 66, 60, 59,\n",
            "        12,  1,  3,  3, 52, 63, 80,  1, 56, 73, 60,  1, 80, 70, 76,  1, 74, 56,\n",
            "        59, 12,  1, 47, 70, 79, 80, 29,  3,  3,  0,  0, 47, 70, 79, 80,  1, 75,\n",
            "        70, 67, 59,  1, 31, 64, 67, 67, 80,  1, 56, 57, 70, 76, 75,  1, 75, 63,\n",
            "        60,  1, 64, 58, 80,  1, 63, 64, 67, 67,  1, 56, 69, 59,  1, 63, 70, 78,\n",
            "         1, 74, 63, 60,  1, 58, 70, 76, 67, 59, 69,  7, 75,  1, 58, 67, 64, 68,\n",
            "        57,  1, 64, 75, 14,  1, 31, 64, 67, 67, 80,  1, 74, 56, 64, 59, 12,  1,\n",
            "         3,  3, 38,  1, 63, 56, 77, 60,  1, 56, 69,  1, 64, 59, 60, 56,  2,  1,\n",
            "        41, 60, 75,  7, 74,  1, 61, 64, 69, 59])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "QbapOMuUeEBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9g6oC7eehMW",
        "outputId": "e76acb03-eb0c-4a6a-f84a-15daa45fb247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3, 48, 71, 70, 75, 14,  1, 48, 71])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-KkC9FveqAq",
        "outputId": "1d1af2b5-068c-4582-e49d-0f35df297ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([3]) the target: 48\n",
            "when input is tensor([ 3, 48]) the target: 71\n",
            "when input is tensor([ 3, 48, 71]) the target: 70\n",
            "when input is tensor([ 3, 48, 71, 70]) the target: 75\n",
            "when input is tensor([ 3, 48, 71, 70, 75]) the target: 14\n",
            "when input is tensor([ 3, 48, 71, 70, 75, 14]) the target: 1\n",
            "when input is tensor([ 3, 48, 71, 70, 75, 14,  1]) the target: 48\n",
            "when input is tensor([ 3, 48, 71, 70, 75, 14,  1, 48]) the target: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independant sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for prediction?\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension\n",
        "    context = xb[b, :t+1]\n",
        "    traget = yb[b,t]\n",
        "    print(f\"when input is {context.tolist()} the target: {traget}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS7cJO0NfK0n",
        "outputId": "0728928e-f927-492e-9c1f-eeec8a7b895c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[73, 70, 68,  1, 57, 60, 63, 64],\n",
            "        [70, 76, 75, 14,  0,  0, 49, 63],\n",
            "        [44, 69, 58, 60,  1, 76, 71, 70],\n",
            "        [56, 69, 75, 64, 58, 64, 71, 56]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[70, 68,  1, 57, 60, 63, 64, 69],\n",
            "        [76, 75, 14,  0,  0, 49, 63, 60],\n",
            "        [69, 58, 60,  1, 76, 71, 70, 69],\n",
            "        [69, 75, 64, 58, 64, 71, 56, 75]])\n",
            "----\n",
            "when input is [73] the target: 70\n",
            "when input is [73, 70] the target: 68\n",
            "when input is [73, 70, 68] the target: 1\n",
            "when input is [73, 70, 68, 1] the target: 57\n",
            "when input is [73, 70, 68, 1, 57] the target: 60\n",
            "when input is [73, 70, 68, 1, 57, 60] the target: 63\n",
            "when input is [73, 70, 68, 1, 57, 60, 63] the target: 64\n",
            "when input is [73, 70, 68, 1, 57, 60, 63, 64] the target: 69\n",
            "when input is [70] the target: 76\n",
            "when input is [70, 76] the target: 75\n",
            "when input is [70, 76, 75] the target: 14\n",
            "when input is [70, 76, 75, 14] the target: 0\n",
            "when input is [70, 76, 75, 14, 0] the target: 0\n",
            "when input is [70, 76, 75, 14, 0, 0] the target: 49\n",
            "when input is [70, 76, 75, 14, 0, 0, 49] the target: 63\n",
            "when input is [70, 76, 75, 14, 0, 0, 49, 63] the target: 60\n",
            "when input is [44] the target: 69\n",
            "when input is [44, 69] the target: 58\n",
            "when input is [44, 69, 58] the target: 60\n",
            "when input is [44, 69, 58, 60] the target: 1\n",
            "when input is [44, 69, 58, 60, 1] the target: 76\n",
            "when input is [44, 69, 58, 60, 1, 76] the target: 71\n",
            "when input is [44, 69, 58, 60, 1, 76, 71] the target: 70\n",
            "when input is [44, 69, 58, 60, 1, 76, 71, 70] the target: 69\n",
            "when input is [56] the target: 69\n",
            "when input is [56, 69] the target: 75\n",
            "when input is [56, 69, 75] the target: 64\n",
            "when input is [56, 69, 75, 64] the target: 58\n",
            "when input is [56, 69, 75, 64, 58] the target: 64\n",
            "when input is [56, 69, 75, 64, 58, 64] the target: 71\n",
            "when input is [56, 69, 75, 64, 58, 64, 71] the target: 56\n",
            "when input is [56, 69, 75, 64, 58, 64, 71, 56] the target: 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaqEL4huhf8F",
        "outputId": "91758f37-a9a2-4dfa-c08a-658ed0a2e12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[73, 70, 68,  1, 57, 60, 63, 64],\n",
            "        [70, 76, 75, 14,  0,  0, 49, 63],\n",
            "        [44, 69, 58, 60,  1, 76, 71, 70],\n",
            "        [56, 69, 75, 64, 58, 64, 71, 56]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # idx and targets are both (B, T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C) # since cross_entropy requires C in 2nd position\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "idx = torch.zeros((1, 1), dtype=torch.long)\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-N6E1TahbaQ",
        "outputId": "042892c0-ecc0-434f-84db-f79c966bd8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 101])\n",
            "tensor(5.3060, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "UX“'h.h5L:hTGR'd$C04Ž™vv.s”V,r˜SlJ<p™fmârWph:‹XG'n\"g<;Ž#D”f¦83WNvAD6f©a?ff­rE7bQnPjA'ðD4#uÂ\n",
            "ql&!Â:lg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "IRpwgP_enX5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000):\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-kGIMP_nhwv",
        "outputId": "6a447848-53dc-4675-8b2c-0fbb2ebd3393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.235708475112915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nnmFMfBoCzV",
        "outputId": "fd73bf16-7c72-4ef2-8211-4d83cbc83b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\"\"\n",
            "We kit kit chad cheapule t thululy bire foushe owand.\n",
            "\n",
            "Timar hete Lin a \n",
            "One.\n",
            "Joul t!\"It Thidou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-attention"
      ],
      "metadata": {
        "id": "ft7PnZ2KqE2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B, T, C = 4, 8, 32 # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "\n",
        "# single head self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x) # (B, T, 16)\n",
        "q = query(x) # (B, T, 16)\n",
        "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58yp9ueGqDj-",
        "outputId": "c18876cc-609b-4b03-8710-c7ac810a4f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sSWx6ajw21n",
        "outputId": "e300fc5e-72fa-4ce0-b928-f334804d2edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
        "# bow = bag of words\n",
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b, :t+1] # (t, C)\n",
        "        xbow[b, t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "X9uL5_O6qqG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgu8KjwPsjow",
        "outputId": "c82cee92-f425-4523-e8e4-4593ca426f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QGMUq2Eul-x",
        "outputId": "5679cbbd-90e2-4fbf-95e8-c991350a3f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0], xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMWepnCztUge",
        "outputId": "2afa8ab6-a08a-4172-852f-0427a44a87d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0, 10, (3, 2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0zfZCDArvSt",
        "outputId": "2964a008-1c88-4b13-b184-adf0ad967731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNorm1d:\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1, device=None, dtype=None):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "      xmean = x.mean(1, keepdim=True) # batch mean\n",
        "      xvar = x.var(1, keepdim=True) # batch variance\n",
        "      xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "      self.out = self.gamma * xhat + self.beta\n",
        "      return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = BatchNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch of 32 samples of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgAwfSsq2sbW",
        "outputId": "8bed9176-4872-43ad-a171-7bcfe5bd6b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PORzmFJw3ppb",
        "outputId": "dbce3764-9690-4bec-fc95-3b5f210c8960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gJyl9cl3x1L",
        "outputId": "da1f6f8e-4ab8-4401-9fae-a9efc3288cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ]
}